# Quantization settings
QuantType: '4bitsym' # 'Ternary', 'Binary', 'BinaryBalanced', '2bitsym', '4bit', '4bitsym', '8bit', 'None", 'FP130' 
BPW : 4
NormType: 'RMS' # 'RMS', 'Lin', 'BatchNorm'
WScale: 'PerTensor' # 'PerTensor', 'PerOutput'
quantscale: 0.25  # How to scale the stddev of each tensor relative to the max value

# Learning parameters
batch_size: 128
num_epochs: 60
scheduler: "Cosine" # "StepLR", "Cosine"
learning_rate: 0.001
lr_decay: 0.1     # lr_decay and step size are not used with cosine scheduler
step_size: 10

# Data augmentation
augmentation: True
rotation1: 10  # rotation1 and rotation2 are used for data augmentation
rotation2: 10

# Model parameters
network_width1: 16
network_width2: 16
network_width3: 0

# name
runtag: "opt_" # runtag is prefix for runname